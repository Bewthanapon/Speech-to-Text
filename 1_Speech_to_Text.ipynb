{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0guVkmaOC0MLEwj30tkW3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bewthanapon/Speech-to-Text/blob/main/1_Speech_to_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q0LqbxRYISYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4edadc43-6561-4776-8e34-a3e106851956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar  6 18:27:05 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install & Import Library"
      ],
      "metadata": {
        "id": "L24t2z0ihYKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGFSfes-oCFP",
        "outputId": "88c345d3-c61b-4d50-bc82-59c8e7d00ffe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803373 sha256=f5e606f3460ac207aaea8a53d74759adc85819f60748b59b1db7ec76ef940388\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pythainlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AZG8ZFEoHny",
        "outputId": "c274241f-1ced-412c-fdf7-33ed33d9fb03"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pythainlp\n",
            "  Downloading pythainlp-5.1.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from pythainlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->pythainlp) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->pythainlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->pythainlp) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->pythainlp) (2025.1.31)\n",
            "Downloading pythainlp-5.1.0-py3-none-any.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pythainlp\n",
            "Successfully installed pythainlp-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOAIR5wUwGZg",
        "outputId": "dc2fdc5a-94f1-431e-f0bb-f6aab02e9af4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.1.0 rapidfuzz-3.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- whisper: OpenAI's automatic speech recognition (ASR) model.\n",
        "- librosa: A library for analyzing and processing audio files.\n",
        "- soundfile: Handles reading and writing audio files.\n",
        "- jiwer: A library for calculating error rates in speech-to-text outputs (WER, CER).\n",
        "- pythainlp.tokenize: Tokenization for Thai language processing."
      ],
      "metadata": {
        "id": "PR1TtE_FlAZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from jiwer import wer, cer\n",
        "from pythainlp.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "-SXkn3UZCliX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 12mWRq6bATH8A0SDFii2z3fqVKcEADCpW"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO8UGGKCIZDN",
        "outputId": "e0f9843d-da68-40cb-d1a0-60940ff59c3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12mWRq6bATH8A0SDFii2z3fqVKcEADCpW\n",
            "To: /content/Telesales Call Recording 2025-02-25 08_23_26.m4a\n",
            "\r  0% 0.00/8.69M [00:00<?, ?B/s]\r100% 8.69M/8.69M [00:00<00:00, 120MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Reference_text__"
      ],
      "metadata": {
        "id": "Pr3_wFO93uk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ref_text = \"สวัสดีค่ะ ขอเรียนสายคุณโชคดี มีเงิน ค่ะดิฉัน นางสาวขายดี ทวีทรัพย์ ติดต่อจากบริษัทคุ้มดีจำกัดในเครือธนาคาร Fin4uทางบริษัทได้จัดทำโครงการพิเศษ ชื่อว่า คุ้มดีมีคืนสะดวกเรียนสายได้สักครู่ไหมคะ สะดวกค่ะ ขอบพระคุณค่ะ หนูขออนุญาตบันทึกสายสนทนานะคะดิฉัน นางสาวขายดี ทวีทรัพย์ เลขที่ใบอนุญาตตัวแทน ตท1902/2025 ค่ะ ทางโครงการขอเรียนเชิญคุณลูกค้าเข้าร่วมโครงการ คุ้มดีมีคืนค่ะซึ่งเป็นโครงการออมทรัพย์พิเศษในรูปแบบการประกันชีวิตสะสมทรัพย์ซึ่งผลประโยชน์ที่ลูกค้าจะได้รับแตกต่างจากที่อื่นๆเพราะการันตีผลตอบแทนรวมตลอดสัญญาสูงสุดถึง 616% ของทุนประกันชีวิตเลยค่ะโดยคุณลูกค้าไม่ต้องใช้เงินก้อนเป็นหมื่นเป็นแสนเลยนะคะเพียงออมเงินทุกๆเดือนเท่าๆกันตัวอย่างเช่น คุณลูกค้าจ่ายเบี้ยเพียงวันละ 90 บาทหรือรายเดือนเดือนละ 2,700 บาทคุณลูกค้าจะได้เงินคืนทุกปีตั้งแต่ปีที่ 1 จนถึงปีที่ 14การันตีรับเงินคืนปีละ 3,200 บาท 14 ปีเท่ากับได้ออมเพิ่มขึ้น 44,800 บาทสิ้นปีที่ 15-24รับเงินการันตีเพิ่มขึ้นไปอีกเป็นปีละ 6,400 บาทรวม 10 ปีเป็นเงินเพิ่ม 64,000 บาทค่ะและเมื่อสิ้นปีที่ 24 ที่ครบอายุสัญญาคุณลูกค้าจะได้เงินออม 384,000 บาทเมื่อรวมกับเงินคืนที่ได้ไปในปีที่ 1 ถึงปีที่ 24แล้วเป็นเงิน 492,800 บาทเลยทีเดียวค่ะที่สำคัญคุณลูกค้าออมเงินเพียงวันละเพียงแค่ 14 ปีแรกแต่มีเงินเพิ่มทุกๆปีถึง 24 ปีเลยค่ะนอกจากนี้ลูกค้ายังสามารถนำยอดเบี้ยที่ชำระในปีที่ 14ปีแรกไปลดหย่อนภาษีในแต่ละปีและยังได้รับความคุ้มครองกรณีลูกค้าสูญเสียชีวิตระหว่างปี 24 นี้ในวงเงินที่สูงถึง 384,000 บาทตั้งแต่วันที่ลูกค้าได้รับการอนุมัติกรมธรรม์ให้อีกด้วยซึ่งเงินก้อนนี้สามารถส่งต่อเป็นมรดกให้ลูกหลานหรือพ่อแม่ได้ค่ะโดยคุ้มครองทุกกรณีของการเสียชีวิตยกเว้นการฆ่าตัวตายปีแรกหรือถูกผู้รับผลประโยชน์ฆาตกรรมค่ะโครงการนี้เป็นประกันชีวิตแบบสะสมทรัพย์ที่ลูกค้าได้รับผลตอบแทนครบทุกด้านทั้งผลตอบแทนในรูปแบบเงินคืนการันตีทุกปี 24 ปีความคุ้มครองชีวิตและประโยชน์ในการลดหย่อนภาษีเราจึงจัดทำโครงการนี้เป็นพิเศษไม่เหมือนใครเพื่อคุณลูกค้าโดยเฉพาะเลยค่ะคุณลูกค้าสนใจเข้าร่วมโครงการหรือไม่คะ แล้วมันเอาไปลงยังไงอะคะมีความเสี่ยงมั้ยคะ ขายดีขอแจ้งคุณลูกค้าแบบนี้นะคะโครงการนี้ไม่ได้เป็นการลงทุนค่ะคุณลูกค้าแต่เป็นการออมเงินและได้สิทธิประโยชน์ในการคุ้มครองชีวิตไปด้วยซึ่งต่างจากการนำเงินไปลงทุนในหุ้นหรือตลาดทุนที่คุณลูกค้าอาจจะเสี่ยงที่จะขาดทุนหรือสูญเสียเงินจากการลงทุนได้ค่ะ  อ๋อ อ๋อ เข้าใจแล้วค่ะ คุณลูกค้ายืนยันเข้าร่วมโครงการนะคะขายดีขอทวนชื่อคุณลูกค้าเป็นคุณโชคดีมีเงิน อยู่บ้านเลขที่ 69/96หมู่บ้านโชคดีทวีสุข ถนนรัชดาภิเษก แขวงดินแดง เขตดินแดง กรุงเทพ 10310ถูกต้องไหมคะ ถูกต้องค่ะ ขอบคุณค่ะ คุณลูกค้าภายใน 15 วันทำการทางบริษัทจะส่งเอกสารรายละเอียดการออมให้เก็บไว้เป็นหลักฐาน โดยเป็นกรมธรรม์ฉบับสะสมทรัพย์ออมเพิ่มสุขที่จะระบุ ผลตอบแทนแบบการันตีทุกๆตัวเลข ตามที่เจ้าหน้าที่แจ้งทั้งหมด จัดส่งตามที่อยู่ที่ระบุไว้เลยไหมคะคุณลูกค้า ได้เลยค่ะ ขอบคุณค่ะคุณลูกค้า ขายดีขอขอบพระคุณคุณลูกค้าเป็นอย่างสูง และขอให้คุณลูกค้ามีสุขภาพแข็งแรงตลอดปี 2525 นะคะ สวัสดีค่ะ สวัสดีค่ะ\""
      ],
      "metadata": {
        "id": "v4RHh5LO3xNN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_text = ''.join(ref_text.split())\n",
        "ref_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "XpJsC6ma3xbT",
        "outputId": "870e34f9-3cf2-49a6-c923-7eae76bc7c4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'สวัสดีค่ะขอเรียนสายคุณโชคดีมีเงินค่ะดิฉันนางสาวขายดีทวีทรัพย์ติดต่อจากบริษัทคุ้มดีจำกัดในเครือธนาคารFin4uทางบริษัทได้จัดทำโครงการพิเศษชื่อว่าคุ้มดีมีคืนสะดวกเรียนสายได้สักครู่ไหมคะสะดวกค่ะขอบพระคุณค่ะหนูขออนุญาตบันทึกสายสนทนานะคะดิฉันนางสาวขายดีทวีทรัพย์เลขที่ใบอนุญาตตัวแทนตท1902/2025ค่ะทางโครงการขอเรียนเชิญคุณลูกค้าเข้าร่วมโครงการคุ้มดีมีคืนค่ะซึ่งเป็นโครงการออมทรัพย์พิเศษในรูปแบบการประกันชีวิตสะสมทรัพย์ซึ่งผลประโยชน์ที่ลูกค้าจะได้รับแตกต่างจากที่อื่นๆเพราะการันตีผลตอบแทนรวมตลอดสัญญาสูงสุดถึง616%ของทุนประกันชีวิตเลยค่ะโดยคุณลูกค้าไม่ต้องใช้เงินก้อนเป็นหมื่นเป็นแสนเลยนะคะเพียงออมเงินทุกๆเดือนเท่าๆกันตัวอย่างเช่นคุณลูกค้าจ่ายเบี้ยเพียงวันละ90บาทหรือรายเดือนเดือนละ2,700บาทคุณลูกค้าจะได้เงินคืนทุกปีตั้งแต่ปีที่1จนถึงปีที่14การันตีรับเงินคืนปีละ3,200บาท14ปีเท่ากับได้ออมเพิ่มขึ้น44,800บาทสิ้นปีที่15-24รับเงินการันตีเพิ่มขึ้นไปอีกเป็นปีละ6,400บาทรวม10ปีเป็นเงินเพิ่ม64,000บาทค่ะและเมื่อสิ้นปีที่24ที่ครบอายุสัญญาคุณลูกค้าจะได้เงินออม384,000บาทเมื่อรวมกับเงินคืนที่ได้ไปในปีที่1ถึงปีที่24แล้วเป็นเงิน492,800บาทเลยทีเดียวค่ะที่สำคัญคุณลูกค้าออมเงินเพียงวันละเพียงแค่14ปีแรกแต่มีเงินเพิ่มทุกๆปีถึง24ปีเลยค่ะนอกจากนี้ลูกค้ายังสามารถนำยอดเบี้ยที่ชำระในปีที่14ปีแรกไปลดหย่อนภาษีในแต่ละปีและยังได้รับความคุ้มครองกรณีลูกค้าสูญเสียชีวิตระหว่างปี24นี้ในวงเงินที่สูงถึง384,000บาทตั้งแต่วันที่ลูกค้าได้รับการอนุมัติกรมธรรม์ให้อีกด้วยซึ่งเงินก้อนนี้สามารถส่งต่อเป็นมรดกให้ลูกหลานหรือพ่อแม่ได้ค่ะโดยคุ้มครองทุกกรณีของการเสียชีวิตยกเว้นการฆ่าตัวตายปีแรกหรือถูกผู้รับผลประโยชน์ฆาตกรรมค่ะโครงการนี้เป็นประกันชีวิตแบบสะสมทรัพย์ที่ลูกค้าได้รับผลตอบแทนครบทุกด้านทั้งผลตอบแทนในรูปแบบเงินคืนการันตีทุกปี24ปีความคุ้มครองชีวิตและประโยชน์ในการลดหย่อนภาษีเราจึงจัดทำโครงการนี้เป็นพิเศษไม่เหมือนใครเพื่อคุณลูกค้าโดยเฉพาะเลยค่ะคุณลูกค้าสนใจเข้าร่วมโครงการหรือไม่คะแล้วมันเอาไปลงยังไงอะคะมีความเสี่ยงมั้ยคะขายดีขอแจ้งคุณลูกค้าแบบนี้นะคะโครงการนี้ไม่ได้เป็นการลงทุนค่ะคุณลูกค้าแต่เป็นการออมเงินและได้สิทธิประโยชน์ในการคุ้มครองชีวิตไปด้วยซึ่งต่างจากการนำเงินไปลงทุนในหุ้นหรือตลาดทุนที่คุณลูกค้าอาจจะเสี่ยงที่จะขาดทุนหรือสูญเสียเงินจากการลงทุนได้ค่ะอ๋ออ๋อเข้าใจแล้วค่ะคุณลูกค้ายืนยันเข้าร่วมโครงการนะคะขายดีขอทวนชื่อคุณลูกค้าเป็นคุณโชคดีมีเงินอยู่บ้านเลขที่69/96หมู่บ้านโชคดีทวีสุขถนนรัชดาภิเษกแขวงดินแดงเขตดินแดงกรุงเทพ10310ถูกต้องไหมคะถูกต้องค่ะขอบคุณค่ะคุณลูกค้าภายใน15วันทำการทางบริษัทจะส่งเอกสารรายละเอียดการออมให้เก็บไว้เป็นหลักฐานโดยเป็นกรมธรรม์ฉบับสะสมทรัพย์ออมเพิ่มสุขที่จะระบุผลตอบแทนแบบการันตีทุกๆตัวเลขตามที่เจ้าหน้าที่แจ้งทั้งหมดจัดส่งตามที่อยู่ที่ระบุไว้เลยไหมคะคุณลูกค้าได้เลยค่ะขอบคุณค่ะคุณลูกค้าขายดีขอขอบพระคุณคุณลูกค้าเป็นอย่างสูงและขอให้คุณลูกค้ามีสุขภาพแข็งแรงตลอดปี2525นะคะสวัสดีค่ะสวัสดีค่ะ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Whisper Model__"
      ],
      "metadata": {
        "id": "NzPCEcSOXlPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Whisper model.\n",
        "model = whisper.load_model(\"large\") # large / medium / small / base / tiny"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBtEla17YCl8",
        "outputId": "81973d4e-c96b-48bd-8acd-2547ab8e95ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [00:41<00:00, 74.5MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the audio file.\n",
        "audio_path = '/content/Telesales Call Recording 2025-02-25 08_23_26.m4a'\n",
        "\n",
        "audio, sr = librosa.load(audio_path, sr=16000, mono=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nbdFwpYYCqq",
        "outputId": "c39c6d83-51fa-409c-debc-9053640456dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a3d1386bc44e>:4: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save audio to a temporary .wav file for Whisper.\n",
        "temp_wav = 'temp_audio.wav'\n",
        "sf.write(temp_wav, audio, sr)"
      ],
      "metadata": {
        "id": "1b9vgM36XlrE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe audio using Whisper.\n",
        "%%time\n",
        "result = model.transcribe(temp_wav, language='th')\n",
        "transcription = result['text']\n",
        "\n",
        "print(\"Transcription:\", transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhoNjf-2Xltr",
        "outputId": "b7835d6a-b52f-4fe5-dbde-d625e211a332"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription: สวัสดีค่ะ ขอเรียนสายคุณโชคดีมีเงินค่ะดิฉัน นางสาวขายดีทวีซับ ติดต่อจากบริษัทคุ้มดีจำกัดในเครือธนาคาร Fin4uทางบริษัทได้จัดทำโครงการพิเศษ ชื่อว่า คุ้มดีมีคืนสะดวกเรียนสายได้สักครู่ไหมคะสะดวกค่ะออกพระคุณค่ะหนูขออนุญาตบันทึกสายสนทนานะคะดิฉัน นางสาวขายดีทวีซับ เลขที่ใบอนุญาต ตัวแทน ต่อท. 1902-2025 ค่ะทางโครงการขอเรียนเชิญคุณลูกค้าเข้าร่วมโครงการ คุ้มดีมีคืนค่ะซึ่งเป็นโครงการออมซับพิเศษในรูปแบบการประกันชีวิตสะสมซับซึ่งผลประโยชน์ที่ลูกค้าได้เชิญค่ะคุณลูกค้าจะได้รับแตกต่างจากที่อื่นๆเพราะการันตีผลตอบแทนรวมตลอดสัญญาสูงสุดถึง 616% ของทุนประกันชีวิตเลยค่ะโดยคุณลูกค้าไม่ต้องใช้เงินก้อนเป็นหมื่นเป็นแสนเลยนะคะเพียงออมเงินทุกๆเดือนเท่าๆกันตัวอย่างเช่น คุณลูกค้าจ่ายเบี้ยเพียงวันละ 90 บาทหรือลายเดือนเดือนละ 2,700 บาทคุณลูกค้าจะได้เงินคืนทุกปีตั้งแต่ปีที่-1 จนถึง ปีที่ 14การันตีรับเงินคืน ปีละ 3,200 บาท เท่ากับได้ออมเพิ่มขึ้น 44,800 บาทสิ้นปีที่ 15-24 รับเงินการันตีเพิ่มขึ้นไปอีกเป็นปีละ 6,400 บาทรวม 10 ปีเป็นเงินเพิ่ม 64,000 บาทค่ะและเมื่อสิ้นปีที่ 24 ที่ครบอายุสัญญาคุณลูกค้าจะได้เงินออม 384,000 บาทเมื่อรวมกับเงินคืนที่ได้ไปในปีที่ 1 ถึงปีที่ 24แล้วเป็นเงิน 492,800 บาทเลยทีเดียวค่ะที่สำคัญคุณลูกค้าออมเงินเพียง กวนละเพียงแค่ 14 ปีแรกแต่มีเงินเข้มทุก ๆปีถึง 24 ปีเลยค่ะนอกจากนี้ลูกค้ายังสามารถหนำยอดเปี้ย pullในปีที่ 14 ปีแรกไปลดยนต์ภาษีในแต่ละปีและยังได้รับความคุ้มครองงรีลูกค้าศูนย์เสียชีวิตระหว่างปี 24ในวงเงินที่สูงถึง 384,000 บาทตั้งแต่วันที่ลูกค้าได้รับการอนุมัติกรมทันให้อีกด้วยซึ่งเงินก้อนนี้สามารถส่งต่อเป็นมรดกให้ลูกหลานหรือพ่อแม่ได้ค่ะโดยคุ้มครองทุกกรณีของการเสียชีวิตยกเว้นการฆ่าตัวตายปีแรกหรือถูกผู้รับผลประโยชน์ฆาตกรรมค่ะโครงการนี้เป็นประกันชีวิตแบบสะสมซับที่ลูกค้าได้รับผลตอบแทนครบทุกด้านทั้งผลตอบแทนในรูปแบบเงินคืนการันตีทุกปีด้วย 24 ปีความคุ้มครองชีวิตและประโยชน์ในการลดหย่อนภาษีเราจึงจัดทำโครงการนี้เป็นพิเศษไม่เหมือนใครเพื่อ คุณลูกค้าโดยเฉพาะเลยค่ะคุณลูกค้าสนใจเข้าร่วมโครงการหรือไม่คะแล้วมันเอาไปรnder อย่าง ไง คะ แล้วมีความเสี่ยง ไหม คะขายดีขอแจ้งคนลูกค้าแบบนี้นะคะ โครงการนี้ไม่ได้เป็นการลงทุน ค่ะคนลูกค้า แต่เป็นการออมเงิน และได้สิทธิประโยชน์ในการคุ้มครองชีวิตไปด้วยซึ่งต่างจากการนำเงินไปลงทุนในหุ้น หรือตลาดทุนที่คุณลูกค้าอาจจะเสี่ยงที่จะขาดทุนหรือศูนย์เสียเงินจากการลงทุนได้ kiss énorme notอยู่บ้านเลขที่ 69-96 หมู่บ้านโชคดี ทวีสุก ถนนรัชดา พิเศษ แขวงดินแดง เขตดินแดง กรุงเทพ 10310 ถูกต้องไหมคะ?ถูกต้องค่ะขอบคุณค่ะคุณลูกค้า ภายใน 15 วันทำการ ทางบริษัทจะส่งเอกสารรายละเอียดการออมให้เก็บไว้เป็นหลักฐานโดยเป็นกรมธรรมชาบับสะสมทรัพย์ ออมเพิ่มสุขที่จะระบุผลตอบแทนแบบการันตีทุกๆตัวเลขตามที่เจ้าหน้าที่แจ้งทั้งหมด จัดส่งตามที่อยู่ที่ระบุไว้เลยไหมคะคุณลูกค้า?ได้เลยค่ะขอบคุณค่ะคุณลูกค้า ขายดีขอขอบพระคุณคุณลูกค้าเป็นอย่างสูงและขอให้คุณลูกค้ามีสุขภาพแข็งแรงตลอดปี 2525 นะคะ สวัสดีค่ะสวัสดีค่ะ\n",
            "CPU times: user 5min 13s, sys: 528 ms, total: 5min 14s\n",
            "Wall time: 5min 15s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_large = transcription\n",
        "text_large = ''.join(text_large.split())\n",
        "text_large"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "fgKLcmNENIz1",
        "outputId": "19081757-5d56-4aa2-a6d1-bda4afff4b82"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'สวัสดีค่ะขอเรียนสายคุณโชคดีมีเงินค่ะดิฉันนางสาวขายดีทวีซับติดต่อจากบริษัทคุ้มดีจำกัดในเครือธนาคารFin4uทางบริษัทได้จัดทำโครงการพิเศษชื่อว่าคุ้มดีมีคืนสะดวกเรียนสายได้สักครู่ไหมคะสะดวกค่ะออกพระคุณค่ะหนูขออนุญาตบันทึกสายสนทนานะคะดิฉันนางสาวขายดีทวีซับเลขที่ใบอนุญาตตัวแทนต่อท.1902-2025ค่ะทางโครงการขอเรียนเชิญคุณลูกค้าเข้าร่วมโครงการคุ้มดีมีคืนค่ะซึ่งเป็นโครงการออมซับพิเศษในรูปแบบการประกันชีวิตสะสมซับซึ่งผลประโยชน์ที่ลูกค้าได้เชิญค่ะคุณลูกค้าจะได้รับแตกต่างจากที่อื่นๆเพราะการันตีผลตอบแทนรวมตลอดสัญญาสูงสุดถึง616%ของทุนประกันชีวิตเลยค่ะโดยคุณลูกค้าไม่ต้องใช้เงินก้อนเป็นหมื่นเป็นแสนเลยนะคะเพียงออมเงินทุกๆเดือนเท่าๆกันตัวอย่างเช่นคุณลูกค้าจ่ายเบี้ยเพียงวันละ90บาทหรือรายเดือนเดือนละ2,700บาทคุณลูกค้าจะได้เงินคืนทุกปีตั้งแต่ปีที่1จนถึงปีที่14การันตีรับเงินคืนปีละ3,200บาท14ปีเท่ากับได้ออมเพิ่มขึ้น44,800บาทสิ้นปีที่15-24รับเงินการันตีเพิ่มขึ้นไปอีกเป็นปีละ6,400บาทรวม10ปีเป็นเงินเพิ่ม64,000บาทและเมื่อสิ้นปีที่24ที่ครบอายุสัญญาคุณลูกค้าจะได้เงินออม384,000บาทเมื่อรวมกับเงินคืนที่ได้ไปในปีที่1ถึงปีที่24แล้วเป็นเงิน492,800บาทเลยทีเดียวค่ะที่สำคัญคุณลูกค้าออมเงินเพียงวันละเพียงแค่14ปีแรกแต่มีเงินเพิ่มทุกๆปีถึง24ปีเลยค่ะนอกจากนี้ลูกค้ายังสามารถนำยอดเบี้ยที่ชำระในปีที่14ปีแรกไปลดยนต์ภาษีในแต่ละปีและยังได้รับความคุ้มครองกรีย์ลูกค้าสูญเสียชีวิตระหว่างปี24นี้ในวงเงินที่0ถึง384,000บาทตั้งแต่วันที่ลูกค้าได้รับการอนุมัติกรมธรรมทัลให้อีกด้วยซึ่งเงินก้อนนี้สามารถส่งต่อเป็นมรดกให้ลูกหลานหรือพ่อแม่ได้ค่ะโดยคุ้มครองทุกกรณีของการเสียชีวิตยกเว้นการฆ่าตัวตายปีแรกหรือถูกผู้รับผลประโยชน์ฆ่าตกรรมค่ะโครงการนี้เป็นประกันชีวิตแบบสะสมทรัพย์ที่ลูกค้าได้รับผลตอบแทนครบทุกด้านทั้งผลตอบแทนในรูปแบบเงินคืนการันตีทุกปี24ปีความคุ้มครองชีวิตและประโยชน์ในการลดหย่อนภาษีเราจึงจัดทำโครงการนี้เป็นพิเศษไม่เหมือนใครเพื่อคุณลูกค้าโดยเฉพาะเลยค่ะคุณลูกค้าสนใจเข้าร่วมโครงการหรือไม่คะแล้วมันเอาไปลงทุนยังไงคะแล้วมีความเสี่ยงไหมคะขายดีขอแจ้งคุณลูกค้าแบบนี้นะคะโครงการนี้ไม่ได้เป็นการลงทุนค่ะคุณลูกค้าแต่เป็นการออมเงินและได้สิทธิประโยชน์ในการคุ้มครองชีวิตไปด้วยซึ่งต่างจากเกียรติandlogisticsประการในหุ้นหรือตลาดทุนที่ลูกที่คุณลูกค้าอาจจะเสี่ยงที่จะขาดทุนหรือศูนย์เสียเงินจากการลูกทุนได้ค่ะอ๋อข้อใจแล้วค่ะคุณลูกยึนยันเข้าร่วมโครงการนะคะขายดีขอทวนชื่อคุณลูกค้าเป็นคุณโชคดีมีเงินอยู่บ้านเลขที่69-96หมู่บ้านโชคดีทวีสุกถนนรัชดาพิเศษแขวงดินแดงเขตดินแดงปรุงเทพ10310ถูกต้องไหมคะถูกต้องค่ะขอบคุณค่ะคุณลูกค้าภายใน15วันทำการทางบริษัทจะส่งเอกสารรายละเอียดการออมให้เก็บไว้เป็นหลักฐานโดยเป็นกรมธรรมชาบับสะสมทรัพย์ออมเพิ่มสุขที่จะระบุผลตอบแทนแบบการันตีทุกๆตัวเลขตามที่เจ้าหน้าที่แจ้งทั้งหมดจัดส่งตามที่อยู่ที่ระบุไว้เลยไหมคะคุณลูกค้าได้เลยค่ะขอบคุณค่ะคุณลูกค้าขายดีขอขอบพระคุณคุณลูกค้าเป็นอย่างสูงและขอให้คุณลูกค้ามีสุขภาพแข็งแรงตลอดปี2525นะคะสวัสดีค่ะสวัสดีค่ะ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Evaluation__"
      ],
      "metadata": {
        "id": "lw-X3cethxll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original text and transcribed text.\n",
        "reference_text = ref_text\n",
        "hypothesis_text = text_large\n",
        "\n",
        "# Tokenize Thai text before calculating WER and CER.\n",
        "reference_tokens = ' '.join(word_tokenize(reference_text, engine='newmm'))\n",
        "hypothesis_tokens = ' '.join(word_tokenize(hypothesis_text, engine='newmm'))\n",
        "\n",
        "# Calculate %WER and %CER.\n",
        "wer_score = wer(reference_tokens, hypothesis_tokens) * 100\n",
        "cer_score = cer(reference_text, hypothesis_text) * 100\n",
        "\n",
        "print(f\"Word Error Rate (WER): {wer_score:.2f}%\")\n",
        "print(f\"Character Error Rate (CER): {cer_score:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0WcsSSzNQqz",
        "outputId": "a6d2acbc-275f-46ad-c7fd-3b190543632c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Error Rate (WER): 9.91%\n",
            "Character Error Rate (CER): 4.83%\n"
          ]
        }
      ]
    }
  ]
}